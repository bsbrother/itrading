"""
åŸºäºæ—©ç›˜é‡åŒ–é€‰è‚¡ç­–ç•¥çš„è‚¡ç¥¨é€‰æ‹©å™¨
Base Stock Picker Strategy for Pre-Market Quantitative Stock Selection

åŸºäºæ–‡æ¡£ before_open_pick_adjust_stocks.md ä¸­çš„ç­–ç•¥å®ç°
"""

import os
import logging
import pandas as pd
from typing import Dict, Tuple
import datetime
from datetime import time
from dotenv import load_dotenv

# å¯¼å…¥æ•°æ®æº
import qstock as qs
import tushare as ts
import akshare as ak

from utils import util

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

os.makedirs('/tmp/itrading', exist_ok=True)

class BaseStockPicker:
    """åŸºç¡€è‚¡ç¥¨é€‰æ‹©å™¨ç±»"""
    
    def __init__(self, 
                 min_market_cap: float = 3e9,      # æœ€å°å¸‚å€¼30äº¿
                 max_market_cap: float = 1.5e10,   # æœ€å¤§å¸‚å€¼150äº¿
                 min_price: float = 5,             # æœ€ä½è‚¡ä»·5å…ƒ
                 max_price: float = 50,            # æœ€é«˜è‚¡ä»·50å…ƒ
                 min_turnover: float = 3,          # æœ€ä½æ¢æ‰‹ç‡3%
                 max_turnover: float = 15,         # æœ€é«˜æ¢æ‰‹ç‡15%
                 min_gain: float = 1,              # æœ€ä½æ¶¨å¹…1%
                 max_gain: float = 7,              # æœ€é«˜æ¶¨å¹…7%
                 min_volume_ratio: float = 1.5,    # æœ€ä½é‡æ¯”1.5
                 max_volume_ratio: float = 5,      # æœ€é«˜é‡æ¯”5
                 market_threshold: float = 0.5):   # å¸‚åœºä¸Šæ¶¨å®¶æ•°é˜ˆå€¼50%
        """
        åˆå§‹åŒ–è‚¡ç¥¨é€‰æ‹©å™¨
        
        Args:
            min_market_cap: æœ€å°æµé€šå¸‚å€¼ï¼ˆå…ƒï¼‰
            max_market_cap: æœ€å¤§æµé€šå¸‚å€¼ï¼ˆå…ƒï¼‰
            min_price: æœ€ä½è‚¡ä»·ï¼ˆå…ƒï¼‰
            max_price: æœ€é«˜è‚¡ä»·ï¼ˆå…ƒï¼‰
            min_turnover: æœ€ä½æ¢æ‰‹ç‡ï¼ˆ%ï¼‰
            max_turnover: æœ€é«˜æ¢æ‰‹ç‡ï¼ˆ%ï¼‰
            min_gain: æœ€ä½æ¶¨å¹…ï¼ˆ%ï¼‰
            max_gain: æœ€é«˜æ¶¨å¹…ï¼ˆ%ï¼‰
            min_volume_ratio: æœ€ä½é‡æ¯”
            max_volume_ratio: æœ€é«˜é‡æ¯”
            market_threshold: å¸‚åœºä¸Šæ¶¨å®¶æ•°é˜ˆå€¼
        """
        self.min_market_cap = min_market_cap
        self.max_market_cap = max_market_cap
        self.min_price = min_price
        self.max_price = max_price
        self.min_turnover = min_turnover
        self.max_turnover = max_turnover
        self.min_gain = min_gain
        self.max_gain = max_gain
        self.min_volume_ratio = min_volume_ratio
        self.max_volume_ratio = max_volume_ratio
        self.market_threshold = market_threshold
        
        # åˆå§‹åŒ–æ•°æ®æº
        self._init_data_sources()
    
    def _init_data_sources(self):
        """åˆå§‹åŒ–æ•°æ®æº"""
        try:
            # åŠ è½½ç¯å¢ƒå˜é‡
            load_dotenv(os.path.expanduser('~/apps/iagent/.env'), verbose=True)
            
            # åˆå§‹åŒ–Tushare
            tushare_token = os.getenv("TUSHARE_TOKEN")
            if tushare_token:
                ts.set_token(tushare_token)
                self.ts_pro = ts.pro_api()
                logger.info("Tushare API initialized successfully")
            else:
                logger.warning("TUSHARE_TOKEN not found, using alternative data sources")
                self.ts_pro = None
                
        except Exception as e:
            logger.error(f"Failed to initialize data sources: {e}")
            self.ts_pro = None
        
    def get_market_date_tushare(self, trade_date: str | datetime.date | datetime.datetime) -> pd.DataFrame:
        """
        Get market data by trade date using Tushare Pro API.
        
        Args:
            trade_date: äº¤æ˜“æ—¥æœŸï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²ã€æ—¥æœŸå¯¹è±¡æˆ–æ—¶é—´æˆ³
            
        Returns:
            åŒ…å«è‚¡ç¥¨æ•°æ®çš„DataFrame
        """

        if not self.ts_pro:
            logger.error("Tushare Pro APIæœªé…ç½®ï¼Œæ— æ³•è·å–å¸‚åœºæ•°æ®")
            return pd.DataFrame()
        
        trade_date = util.convert_trade_date(trade_date)
        if not trade_date:
            raise ValueError("æ— æ•ˆçš„äº¤æ˜“æ—¥æœŸæ ¼å¼")
        
        # è·å–å½“æ—¥è¡Œæƒ…æ•°æ®
        daily_data = self.ts_pro.daily(
            trade_date=trade_date,
            fields='ts_code,trade_date,close,open,high,low,pre_close,change,pct_chg,vol,amount,turnover_rate'
        )
        if trade_date != datetime.datetime.now().strftime('%Y%m%d'):
            return daily_data
        
        # è·å–å½“æ—¥è‚¡ç¥¨åˆ—è¡¨å’ŒåŸºæœ¬ä¿¡æ¯
        stock_basic = self.ts_pro.stock_basic(
            exchange='', 
            list_status='L', 
            fields='ts_code,symbol,name,area,industry,market'
        )
        
        if daily_data.empty:
            logger.info("å½“æ—¥æ— äº¤æ˜“æ•°æ®ï¼Œè·å–æœ€è¿‘äº¤æ˜“æ—¥æ•°æ®...")
            last_trade_date = util.last_trading_day(trade_date)
            daily_data = self.ts_pro.daily(
                trade_date=last_trade_date,
                fields='ts_code,trade_date,close,open,high,low,pre_close,change,pct_chg,vol,amount,turnover_rate'
            )
            
        # åˆå¹¶åŸºæœ¬ä¿¡æ¯å’Œè¡Œæƒ…æ•°æ®
        df = pd.merge(stock_basic, daily_data, on='ts_code', how='inner')
            
        # è·å–å®æ—¶æ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        # è·å–èµ„é‡‘æµå‘æ•°æ®ä½œä¸ºé‡æ¯”çš„æ›¿ä»£
        moneyflow = self.ts_pro.moneyflow(
            trade_date=trade_date,
            fields='ts_code,buy_sm_vol,sell_sm_vol'
        )
        df = pd.merge(df, moneyflow, on='ts_code', how='left')
    
        # æ ‡å‡†åŒ–åˆ—åä»¥åŒ¹é…ç°æœ‰æ ¼å¼
        df = self._standardize_tushare_columns(df)
            
        logger.info(f"âœ… Tushare Pro APIæˆåŠŸè·å–åˆ° {len(df)} åªè‚¡ç¥¨æ•°æ®")
        return df


    def get_market_data(self, trade_date: str | datetime.date | datetime.datetime) -> pd.DataFrame:
        """
        Get market data by trade date.

        Use the following data sources API by orders: Qstock API -> Akshare API -> Tushare Pro API -> Mock data
        
        Args:
            trade_date: äº¤æ˜“æ—¥æœŸï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²ã€æ—¥æœŸå¯¹è±¡æˆ–æ—¶é—´æˆ³

        Returns:
            åŒ…å«è‚¡ç¥¨æ•°æ®çš„DataFrame
        """

        trade_date = util.convert_trade_date(trade_date)
        if trade_date < datetime.datetime.now().strftime('%Y%m%d'):
            logger.info(f"è·å– {trade_date} çš„å¸‚åœºæ•°æ® by tushare API and return.")
            return self.get_market_data_tushare(trade_date)
        

        if time(9, 30) <= datetime.datetime.now().time() <= time(11, 30) or \
              time(13, 0) <= datetime.datetime.now().time() <= time(15, 0):
            logger.info(f"è·å– {trade_date} çš„å¸‚åœºæ•°æ® realtime data by qstock/akshare/tushare API.")

        if time(8, 0) <= datetime.datetime.now().time() <= time(9, 30) or \
              time(15, 0) <= datetime.datetime.now().time() <= time(16, 30):
            logger.warning("pre-market(8:00 - before 9:30) or post-market(after 15:00 - 16:30) will init or sync stock data, APIs will connect close error.")

         
        # ç¬¬1ä¼˜å…ˆçº§ï¼šä½¿ç”¨Qstock API
        try:
            logger.info("ç¬¬1ä¼˜å…ˆçº§ï¼šå°è¯•ä½¿ç”¨Qstock APIè·å–å¸‚åœºæ•°æ®...")
            df = qs.market_realtime()
            logger.info(f"âœ… Qstock APIæˆåŠŸè·å–åˆ° {len(df)} åªè‚¡ç¥¨çš„å®æ—¶æ•°æ®")
            return df
        except Exception as e2:
            logger.error(f"âŒ Qstock APIå¤±è´¥: {e2}")
            
        # ç¬¬2ä¼˜å…ˆçº§ï¼šä½¿ç”¨Akshare API
        try:
            logger.info("ç¬¬2ä¼˜å…ˆçº§ï¼šå°è¯•ä½¿ç”¨Akshare APIè·å–å¸‚åœºæ•°æ®...")
            df = ak.stock_zh_a_spot() # stock_zh_a_spot_em() cause connect closed error.
            logger.info(f"âœ… Akshare APIæˆåŠŸè·å–åˆ° {len(df)} åªè‚¡ç¥¨æ•°æ®")
            
            # æ ‡å‡†åŒ–akshareçš„åˆ—åä»¥åŒ¹é…æ ¼å¼
            df = self._standardize_akshare_columns(df)
            return df
        except Exception as e:
            logger.error(f"âŒ Akshare APIå¤±è´¥: {e}")

        try:
            logger.info("ç¬¬3ä¼˜å…ˆçº§ï¼šå°è¯•ä½¿ç”¨Tushare APIè·å–å¸‚åœºæ•°æ®...")
            return self.get_market_date_tushare(trade_date)
        except Exception as e:
            logger.error(f"âŒ Tushare Pro APIå¤±è´¥: {e}")
            # æœ€åå¤‡ç”¨ï¼šç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤º/æµ‹è¯•
            logger.warning("ğŸ”„ æ‰€æœ‰APIæ•°æ®æºä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º/æµ‹è¯•")
            return self._generate_mock_data()
            
    
    def _generate_mock_data(self) -> pd.DataFrame:
        """
        ç”Ÿæˆæ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®ç”¨äºæ¼”ç¤º
        
        Returns:
            åŒ…å«æ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®çš„DataFrame
        """
        import numpy as np
        
        # åˆ›å»ºä¸€äº›æ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®
        mock_stocks = [
            ['000001', 'å¹³å®‰é“¶è¡Œ', 12.50, 12.60, 12.80, 12.30, 12.45, 2.1, 1.2, 8.5, 1000000, 1.26e9, 12.34, 5.2e10, 4.8e10],
            ['000002', 'ä¸‡ç§‘A', 18.20, 18.50, 18.65, 18.10, 18.15, 1.8, 0.9, 12.3, 800000, 1.48e9, 18.12, 2.1e11, 1.95e11],
            ['000858', 'äº”ç²®æ¶²', 165.30, 168.20, 170.00, 164.50, 166.80, 1.2, 1.5, 22.1, 500000, 8.41e9, 163.45, 6.5e11, 6.2e11],
            ['600036', 'æ‹›å•†é“¶è¡Œ', 45.80, 46.20, 46.50, 45.60, 45.95, 0.8, 1.1, 9.2, 300000, 1.38e9, 45.75, 1.8e12, 1.7e12],
            ['600519', 'è´µå·èŒ…å°', 1680.50, 1705.30, 1720.00, 1675.20, 1690.80, 0.3, 2.1, 35.8, 100000, 1.71e10, 1672.40, 2.1e12, 2.0e12],
            ['000858', 'æ¯”äºšè¿ª', 280.40, 285.60, 290.00, 278.50, 282.30, 2.5, 1.8, 18.6, 600000, 1.71e9, 277.80, 8.2e11, 7.8e11],
            ['002415', 'æµ·åº·å¨è§†', 35.60, 36.20, 36.80, 35.40, 35.85, 1.5, 1.3, 15.2, 400000, 1.45e9, 35.45, 3.4e11, 3.2e11],
            ['300059', 'ä¸œæ–¹è´¢å¯Œ', 18.90, 19.20, 19.50, 18.70, 19.10, 3.2, 2.1, 28.5, 2000000, 3.84e9, 18.75, 2.9e11, 2.8e11],
            ['600050', 'ä¸­å›½è”é€š', 5.80, 5.90, 6.00, 5.75, 5.85, 2.8, 1.4, 18.9, 1500000, 8.85e8, 5.75, 1.8e11, 1.7e11],
            ['601318', 'ä¸­å›½å¹³å®‰', 62.30, 63.50, 64.00, 62.00, 62.80, 1.6, 1.0, 11.8, 800000, 5.08e9, 62.15, 1.1e12, 1.0e12]
        ]
        
        columns = ['ä»£ç ', 'åç§°', 'æ˜¨æ”¶', 'æœ€æ–°', 'æœ€é«˜', 'æœ€ä½', 'ä»Šå¼€', 'æ¶¨å¹…', 'æ¢æ‰‹ç‡', 'å¸‚ç›ˆç‡', 'æˆäº¤é‡', 'æˆäº¤é¢', 'é‡æ¯”', 'æ€»å¸‚å€¼', 'æµé€šå¸‚å€¼']
        
        df = pd.DataFrame(mock_stocks, columns=columns)
        
        # è®¡ç®—æ¶¨å¹…
        df['æ¶¨å¹…'] = ((df['æœ€æ–°'] - df['æ˜¨æ”¶']) / df['æ˜¨æ”¶'] * 100).round(2)
        
        # æ·»åŠ ä¸€äº›éšæœºæ€§
        np.random.seed(42)
        df['æ¶¨å¹…'] = df['æ¶¨å¹…'] + np.random.normal(0, 0.5, len(df))
        df['æ¶¨å¹…'] = df['æ¶¨å¹…'].round(2)
        
        # é‡æ–°è®¡ç®—æœ€æ–°ä»·
        df['æœ€æ–°'] = (df['æ˜¨æ”¶'] * (1 + df['æ¶¨å¹…'] / 100)).round(2)
        
        logger.info(f"ç”Ÿæˆäº† {len(df)} åªæ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®")
        return df
    
    def check_market_environment(self, df: pd.DataFrame) -> Tuple[bool, float]:
        """
        æ£€æŸ¥å¸‚åœºç¯å¢ƒ
        
        Args:
            df: å¸‚åœºæ•°æ®DataFrame
            
        Returns:
            (æ˜¯å¦é€‚åˆé€‰è‚¡, ä¸Šæ¶¨å®¶æ•°å æ¯”)
        """
        # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
        if df.empty:
            logger.warning("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•åˆ†æå¸‚åœºç¯å¢ƒ")
            return False, 0.0
        
        # æ£€æŸ¥å¸‚åœºæ˜¯å¦å¼€ç›˜ - é€šè¿‡æ¶¨å¹…åˆ—æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®åˆ¤æ–­
        gain_col = None
        possible_gain_cols = ['æ¶¨å¹…', 'æ¶¨è·Œå¹…']  # qstockå’Œakshareçš„æ¶¨å¹…åˆ—å
        
        for col in possible_gain_cols:
            if col in df.columns:
                gain_col = col
                break
        
        if gain_col is None:
            logger.warning("æœªæ‰¾åˆ°æ¶¨å¹…ç›¸å…³åˆ—ï¼Œæ— æ³•åˆ†æå¸‚åœºç¯å¢ƒ")
            return False, 0.0
        
        # æ¸…ç†æ•°æ®ï¼šç¡®ä¿æ¶¨å¹…åˆ—ä¸ºæ•°å€¼ç±»å‹
        try:
            df_clean = df.copy()
            df_clean[gain_col] = pd.to_numeric(df_clean[gain_col], errors='coerce')
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ¶¨å¹…æ•°æ®ï¼ˆåˆ¤æ–­å¸‚åœºæ˜¯å¦å¼€ç›˜ï¼‰
            valid_gain_data = df_clean[df_clean[gain_col].notna()]
            
            if valid_gain_data.empty:
                logger.warning("æ‰€æœ‰æ¶¨å¹…æ•°æ®ä¸ºç©ºï¼Œå¯èƒ½å¸‚åœºå°šæœªå¼€ç›˜")
                # åœ¨å¸‚åœºæœªå¼€ç›˜æ—¶ï¼Œè¿”å›ä¸­æ€§ç»“æœï¼Œå…è®¸è¿›è¡ŒåŸºç¡€ç­›é€‰
                logger.info("å¸‚åœºæœªå¼€ç›˜ï¼Œå°†åŸºäºæ˜¨æ—¥æ”¶ç›˜ä»·è¿›è¡ŒåŸºç¡€ç­›é€‰")
                return True, 0.5  # è¿”å›ä¸­æ€§å¸‚åœºç¯å¢ƒï¼Œå…è®¸é€‰è‚¡ä½†è®¾ç½®ä¿å®ˆé˜ˆå€¼
            
            # è®¡ç®—ä¸Šæ¶¨å®¶æ•°å æ¯”
            up_count = len(valid_gain_data[valid_gain_data[gain_col] > 0])
            total_count = len(valid_gain_data)
            up_ratio = up_count / total_count if total_count > 0 else 0
            
            is_good_market = up_ratio > self.market_threshold
            
            logger.info(f"å¸‚åœºä¸Šæ¶¨å®¶æ•°å æ¯”: {up_ratio:.2%}")
            if is_good_market:
                logger.info("å¸‚åœºç¯å¢ƒè‰¯å¥½ï¼Œé€‚åˆé€‰è‚¡")
            else:
                logger.warning("å¸‚åœºç¯å¢ƒä¸ä½³ï¼Œå»ºè®®è§‚æœ›")
                
            return is_good_market, up_ratio
            
        except Exception as e:
            logger.error(f"åˆ†æå¸‚åœºç¯å¢ƒæ—¶å‡ºé”™: {e}")
            return False, 0.0
    
    def filter_risk_stocks(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è¿‡æ»¤é£é™©è‚¡ç¥¨
        
        Args:
            df: è‚¡ç¥¨æ•°æ®DataFrame
            
        Returns:
            è¿‡æ»¤åçš„DataFrame
        """
        # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
        if df.empty:
            logger.warning("è¾“å…¥æ•°æ®ä¸ºç©ºï¼Œè¿”å›ç©ºDataFrame")
            return df
        
        # æ£€æŸ¥å¿…éœ€åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ['åç§°', 'ä»£ç ']
        missing_cols = [col for col in required_columns if col not in df.columns]
        if missing_cols:
            logger.warning(f"ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}ï¼Œè·³è¿‡é£é™©è¿‡æ»¤")
            return df
        
        try:
            # ç¡®ä¿åˆ—ä¸ºå­—ç¬¦ä¸²ç±»å‹
            df_clean = df.copy()
            df_clean['åç§°'] = df_clean['åç§°'].astype(str)
            df_clean['ä»£ç '] = df_clean['ä»£ç '].astype(str)
            
            # æ’é™¤é—®é¢˜è‚¡ - æ›´ä¸¥æ ¼çš„è¿‡æ»¤è§„åˆ™
            exclude_conditions = (
                df_clean['åç§°'].str.startswith('C') |     # æ–°è‚¡
                df_clean['åç§°'].str.startswith('N') |     # æ–°è‚¡  
                df_clean['åç§°'].str.startswith('*ST') |   # *STè‚¡
                df_clean['åç§°'].str.startswith('ST') |    # STè‚¡
                df_clean['åç§°'].str.startswith('S') |     # Sè‚¡
                df_clean['åç§°'].str.contains('é€€') |      # é€€å¸‚è‚¡
                df_clean['ä»£ç '].str.startswith('C') |     # æ–°è‚¡ä»£ç 
                df_clean['ä»£ç '].str.startswith('N') |     # æ–°è‚¡ä»£ç 
                df_clean['ä»£ç '].str.contains('ST') |      # STè‚¡ä»£ç 
                df_clean['ä»£ç '].str.startswith('*')       # ç‰¹æ®Šæ ‡è®°è‚¡ç¥¨
            )
            
            filtered_df = df_clean[~exclude_conditions]
            logger.info(f"è¿‡æ»¤é£é™©è‚¡ç¥¨åå‰©ä½™ {len(filtered_df)} åªè‚¡ç¥¨")
            
            return filtered_df
            
        except Exception as e:
            logger.error(f"è¿‡æ»¤é£é™©è‚¡ç¥¨æ—¶å‡ºé”™: {e}")
            return df
    
    def apply_selection_criteria(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        åº”ç”¨é€‰è‚¡æ ‡å‡†
        
        Args:
            df: è‚¡ç¥¨æ•°æ®DataFrame
            
        Returns:
            ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨DataFrame
        """
        # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
        if df.empty:
            logger.warning("è¾“å…¥æ•°æ®ä¸ºç©ºï¼Œè¿”å›ç©ºDataFrame")
            return df
        
        # å¤„ç†ä¸åŒæ•°æ®æºçš„åˆ—åå·®å¼‚
        column_mapping = {
            # qstock -> standard name (ä½†ä¿ç•™åŸåˆ—åå¦‚æœæ–°åˆ—åä¸å­˜åœ¨)
            'æ¶¨è·Œå¹…': 'æ¶¨å¹…',
            'å¸‚ç›ˆç‡-åŠ¨æ€': 'å¸‚ç›ˆç‡'
        }
        
        # æ ‡å‡†åŒ–åˆ—åï¼ˆåªæ˜ å°„é‚£äº›ç¡®å®éœ€è¦æ˜ å°„çš„ï¼‰
        df_clean = df.copy()
        for old_col, new_col in column_mapping.items():
            if old_col in df_clean.columns and new_col not in df_clean.columns:
                df_clean = df_clean.rename(columns={old_col: new_col})
        
        # æ£€æŸ¥å¿…éœ€åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ['æµé€šå¸‚å€¼', 'å¸‚ç›ˆç‡']  # åŸºç¡€å¿…éœ€åˆ—
        price_columns = ['æœ€æ–°ä»·', 'æœ€æ–°', 'æ˜¨æ”¶']  # ä»·æ ¼åˆ—ï¼ˆä»»é€‰å…¶ä¸€ï¼‰
        optional_columns = ['æ¶¨å¹…', 'æ¶¨è·Œå¹…', 'é‡æ¯”', 'æ¢æ‰‹ç‡']  # è¿™äº›åˆ—åœ¨å¸‚åœºæœªå¼€ç›˜æ—¶å¯èƒ½ä¸ºç©º
        
        missing_required = [col for col in required_columns if col not in df_clean.columns]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»·æ ¼åˆ—ï¼Œå¹¶æ‰¾åˆ°æœ‰æ•°æ®çš„é‚£ä¸ª
        available_price_cols = []
        for col in price_columns:
            if col in df_clean.columns:
                # æ£€æŸ¥è¯¥åˆ—æ˜¯å¦æœ‰æœ‰æ•ˆæ•°æ®
                valid_count = pd.to_numeric(df_clean[col], errors='coerce').notna().sum()
                if valid_count > 0:
                    available_price_cols.append((col, valid_count))
        
        if missing_required:
            logger.warning(f"ç¼ºå°‘å¿…éœ€åˆ—è¿›è¡Œé€‰è‚¡: {missing_required}")
            return pd.DataFrame()
            
        if not available_price_cols:
            logger.warning("æ²¡æœ‰å¯ç”¨çš„ä»·æ ¼åˆ—ï¼Œæ— æ³•è¿›è¡Œé€‰è‚¡")
            return pd.DataFrame()
        
        # é€‰æ‹©æ•°æ®æœ€å¤šçš„ä»·æ ¼åˆ—
        available_price_cols.sort(key=lambda x: x[1], reverse=True)
        price_col = available_price_cols[0][0]
        
        logger.info(f"ä½¿ç”¨ä»·æ ¼åˆ—: {price_col}")
        
        try:
            # æ¸…ç†æ•°æ®ï¼šç¡®ä¿æ•°å€¼åˆ—ä¸ºæ•°å€¼ç±»å‹
            all_numeric_columns = required_columns + [price_col] + [col for col in optional_columns if col in df_clean.columns]
            for col in all_numeric_columns:
                if col in df_clean.columns:
                    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')
            
            # åªå¯¹åŸºç¡€å¿…éœ€åˆ—åˆ é™¤NaN
            essential_columns = required_columns + [price_col]
            df_clean = df_clean.dropna(subset=essential_columns)
            
            if df_clean.empty:
                logger.warning("æ¸…ç†åŸºç¡€æ•°æ®åä¸ºç©ºï¼Œæ— æ³•åº”ç”¨é€‰è‚¡æ ‡å‡†")
                return df_clean
            
            # ä¸ºå¯é€‰åˆ—å¡«å……é»˜è®¤å€¼ï¼ˆç”¨äºå¸‚åœºæœªå¼€ç›˜çš„æƒ…å†µï¼‰
            if 'æ¶¨å¹…' in df_clean.columns:
                df_clean['æ¶¨å¹…'] = df_clean['æ¶¨å¹…'].fillna(0.0)  # æœªå¼€ç›˜æ—¶æ¶¨å¹…ä¸º0
            else:
                df_clean['æ¶¨å¹…'] = 0.0
                
            if 'é‡æ¯”' in df_clean.columns:
                df_clean['é‡æ¯”'] = df_clean['é‡æ¯”'].fillna(1.0)  # æœªå¼€ç›˜æ—¶é‡æ¯”é»˜è®¤ä¸º1
            else:
                df_clean['é‡æ¯”'] = 1.0
                
            if 'æ¢æ‰‹ç‡' in df_clean.columns:
                df_clean['æ¢æ‰‹ç‡'] = df_clean['æ¢æ‰‹ç‡'].fillna(0.0)  # æœªå¼€ç›˜æ—¶æ¢æ‰‹ç‡ä¸º0
            else:
                df_clean['æ¢æ‰‹ç‡'] = 0.0
            
            # æ£€æŸ¥æ˜¯å¦å¸‚åœºå¼€ç›˜ï¼ˆé€šè¿‡ä»·æ ¼æ•°æ®åˆ¤æ–­ï¼‰
            market_open = price_col == 'æœ€æ–°ä»·' and not df_clean[price_col].isna().all()
            
            if not market_open and price_col != 'æ˜¨æ”¶':
                logger.info("å¸‚åœºæœªå¼€ç›˜ï¼ŒåŸºäºæ˜¨æ—¥æ•°æ®è¿›è¡ŒåŸºç¡€ç­›é€‰")
                # ä½¿ç”¨æ˜¨æ”¶ä»·æ ¼ä»£æ›¿æœ€æ–°ä»·
                if 'æ˜¨æ”¶' in df_clean.columns:
                    df_clean[price_col] = df_clean[price_col].fillna(df_clean['æ˜¨æ”¶'])
                else:
                    logger.warning("æ²¡æœ‰æ˜¨æ”¶ä»·æ ¼æ•°æ®ï¼Œæ— æ³•è¿›è¡Œç­›é€‰")
                    return pd.DataFrame()
            
            # åŸºæœ¬é¢ç­›é€‰
            market_cap_condition = (
                (df_clean['æµé€šå¸‚å€¼'] >= self.min_market_cap) & 
                (df_clean['æµé€šå¸‚å€¼'] <= self.max_market_cap)
            )
            
            price_condition = (
                (df_clean[price_col] >= self.min_price) & 
                (df_clean[price_col] <= self.max_price)
            )
            
            positive_pe_condition = df_clean['å¸‚ç›ˆç‡'] > 0  # ç›ˆåˆ©ä¼ä¸š
            
            # æ ¹æ®å¸‚åœºå¼€ç›˜çŠ¶æ€è°ƒæ•´ç­›é€‰æ¡ä»¶
            if market_open:
                # å¸‚åœºå¼€ç›˜æ—¶åº”ç”¨å®Œæ•´çš„é‡ä»·æŒ‡æ ‡ç­›é€‰
                turnover_condition = (
                    (df_clean['æ¢æ‰‹ç‡'] >= self.min_turnover) & 
                    (df_clean['æ¢æ‰‹ç‡'] <= self.max_turnover)
                )
                
                gain_condition = (
                    (df_clean['æ¶¨å¹…'] >= self.min_gain) & 
                    (df_clean['æ¶¨å¹…'] <= self.max_gain)
                )
                
                volume_ratio_condition = (
                    (df_clean['é‡æ¯”'] >= self.min_volume_ratio) & 
                    (df_clean['é‡æ¯”'] <= self.max_volume_ratio)
                )
                
                # ç»¼åˆç­›é€‰
                selected = df_clean[
                    market_cap_condition & 
                    price_condition & 
                    positive_pe_condition & 
                    turnover_condition & 
                    gain_condition & 
                    volume_ratio_condition
                ]
                
                logger.info(f"åº”ç”¨å®Œæ•´é€‰è‚¡æ ‡å‡†åå‰©ä½™ {len(selected)} åªè‚¡ç¥¨")
            else:
                # å¸‚åœºæœªå¼€ç›˜æ—¶åªåº”ç”¨åŸºæœ¬é¢ç­›é€‰
                selected = df_clean[
                    market_cap_condition & 
                    price_condition & 
                    positive_pe_condition
                ]
                
                logger.info(f"åº”ç”¨åŸºç¡€é€‰è‚¡æ ‡å‡†åå‰©ä½™ {len(selected)} åªè‚¡ç¥¨ï¼ˆå¸‚åœºæœªå¼€ç›˜ï¼‰")
            
            return selected
            
        except Exception as e:
            logger.error(f"åº”ç”¨é€‰è‚¡æ ‡å‡†æ—¶å‡ºé”™: {e}")
            return pd.DataFrame()
    
    def rank_stocks(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å¯¹è‚¡ç¥¨è¿›è¡Œæ’åº
        
        Args:
            df: ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨DataFrame
            
        Returns:
            æ’åºåçš„DataFrame
        """
        if df.empty:
            return df
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡æ¯”æ•°æ®ï¼ˆåˆ¤æ–­å¸‚åœºæ˜¯å¦å¼€ç›˜ï¼‰
        if 'é‡æ¯”' in df.columns and not df['é‡æ¯”'].isna().all() and (df['é‡æ¯”'] != 1.0).any():
            # å¸‚åœºå¼€ç›˜æ—¶æŒ‰é‡æ¯”é™åºæ’åˆ—
            ranked_df = df.sort_values('é‡æ¯”', ascending=False)
            # æ·»åŠ ç»¼åˆå¾—åˆ†
            ranked_df = self._calculate_composite_score(ranked_df)
        else:
            # å¸‚åœºæœªå¼€ç›˜æ—¶æŒ‰å¸‚å€¼æ’åºï¼ˆå°å¸‚å€¼ä¼˜å…ˆï¼‰
            if 'æµé€šå¸‚å€¼' in df.columns:
                ranked_df = df.sort_values('æµé€šå¸‚å€¼', ascending=True)
                logger.info("å¸‚åœºæœªå¼€ç›˜ï¼ŒæŒ‰æµé€šå¸‚å€¼å‡åºæ’åˆ—")
            else:
                ranked_df = df.copy()
        
        return ranked_df
    
    def _calculate_composite_score(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—ç»¼åˆå¾—åˆ†
        
        Args:
            df: è‚¡ç¥¨æ•°æ®DataFrame
            
        Returns:
            æ·»åŠ ç»¼åˆå¾—åˆ†çš„DataFrame
        """
        if df.empty:
            return df
        
        df = df.copy()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„äº¤æ˜“æ•°æ®
        has_trading_data = (
            'é‡æ¯”' in df.columns and not df['é‡æ¯”'].isna().all() and (df['é‡æ¯”'] != 1.0).any()
        )
        
        if has_trading_data:
            # å¸‚åœºå¼€ç›˜æ—¶çš„å®Œæ•´è¯„åˆ†
            # æ ‡å‡†åŒ–å„é¡¹æŒ‡æ ‡ (0-1èŒƒå›´)
            if df['é‡æ¯”'].max() > df['é‡æ¯”'].min():
                df['é‡æ¯”_æ ‡å‡†åŒ–'] = (df['é‡æ¯”'] - df['é‡æ¯”'].min()) / (df['é‡æ¯”'].max() - df['é‡æ¯”'].min())
            else:
                df['é‡æ¯”_æ ‡å‡†åŒ–'] = 0.5
            
            if 'æ¢æ‰‹ç‡' in df.columns and df['æ¢æ‰‹ç‡'].max() > df['æ¢æ‰‹ç‡'].min():
                df['æ¢æ‰‹ç‡_æ ‡å‡†åŒ–'] = (df['æ¢æ‰‹ç‡'] - df['æ¢æ‰‹ç‡'].min()) / (df['æ¢æ‰‹ç‡'].max() - df['æ¢æ‰‹ç‡'].min())
            else:
                df['æ¢æ‰‹ç‡_æ ‡å‡†åŒ–'] = 0.5
            
            # å¤„ç†æ¶¨å¹…åˆ—åå·®å¼‚
            gain_col = 'æ¶¨å¹…' if 'æ¶¨å¹…' in df.columns else 'æ¶¨è·Œå¹…' if 'æ¶¨è·Œå¹…' in df.columns else None
            if gain_col and df[gain_col].max() > df[gain_col].min():
                df['æ¶¨å¹…_æ ‡å‡†åŒ–'] = (df[gain_col] - df[gain_col].min()) / (df[gain_col].max() - df[gain_col].min())
            else:
                df['æ¶¨å¹…_æ ‡å‡†åŒ–'] = 0.5
            
            # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆæƒé‡å¯è°ƒæ•´ï¼‰
            df['ç»¼åˆå¾—åˆ†'] = (
                df['é‡æ¯”_æ ‡å‡†åŒ–'] * 0.4 +      # é‡æ¯”æƒé‡40%
                df['æ¢æ‰‹ç‡_æ ‡å‡†åŒ–'] * 0.3 +    # æ¢æ‰‹ç‡æƒé‡30%
                df['æ¶¨å¹…_æ ‡å‡†åŒ–'] * 0.3        # æ¶¨å¹…æƒé‡30%
            )
            
            # æŒ‰ç»¼åˆå¾—åˆ†é‡æ–°æ’åº
            df = df.sort_values('ç»¼åˆå¾—åˆ†', ascending=False)
        else:
            # å¸‚åœºæœªå¼€ç›˜æ—¶çš„ç®€åŒ–è¯„åˆ†ï¼ˆåŸºäºåŸºæœ¬é¢ï¼‰
            # æŒ‰å¸‚å€¼åå‘æ’åºï¼ˆå°å¸‚å€¼ç»™æ›´é«˜åˆ†ï¼‰
            if 'æµé€šå¸‚å€¼' in df.columns and df['æµé€šå¸‚å€¼'].max() > df['æµé€šå¸‚å€¼'].min():
                df['å¸‚å€¼_æ ‡å‡†åŒ–'] = 1 - (df['æµé€šå¸‚å€¼'] - df['æµé€šå¸‚å€¼'].min()) / (df['æµé€šå¸‚å€¼'].max() - df['æµé€šå¸‚å€¼'].min())
            else:
                df['å¸‚å€¼_æ ‡å‡†åŒ–'] = 0.5
                
            # æŒ‰å¸‚ç›ˆç‡è¯„åˆ†ï¼ˆåˆç†å¸‚ç›ˆç‡ç»™æ›´é«˜åˆ†ï¼‰
            if 'å¸‚ç›ˆç‡' in df.columns:
                # å¸‚ç›ˆç‡åœ¨15-25ä¹‹é—´ç»™æœ€é«˜åˆ†
                pe_scores = []
                for pe in df['å¸‚ç›ˆç‡']:
                    if pd.isna(pe) or pe <= 0:
                        pe_scores.append(0)
                    elif 15 <= pe <= 25:
                        pe_scores.append(1.0)
                    elif 10 <= pe < 15 or 25 < pe <= 35:
                        pe_scores.append(0.8)
                    elif 5 <= pe < 10 or 35 < pe <= 50:
                        pe_scores.append(0.6)
                    else:
                        pe_scores.append(0.3)
                df['å¸‚ç›ˆç‡_æ ‡å‡†åŒ–'] = pe_scores
            else:
                df['å¸‚ç›ˆç‡_æ ‡å‡†åŒ–'] = 0.5
            
            # è®¡ç®—åŸºç¡€ç»¼åˆå¾—åˆ†
            df['ç»¼åˆå¾—åˆ†'] = (
                df['å¸‚å€¼_æ ‡å‡†åŒ–'] * 0.6 +      # å¸‚å€¼æƒé‡60%
                df['å¸‚ç›ˆç‡_æ ‡å‡†åŒ–'] * 0.4      # å¸‚ç›ˆç‡æƒé‡40%
            )
            
            # æŒ‰ç»¼åˆå¾—åˆ†æ’åº
            df = df.sort_values('ç»¼åˆå¾—åˆ†', ascending=False)
        
        return df
    
    def select_stocks(self, max_stocks: int = 10) -> Tuple[pd.DataFrame, Dict]:
        """
        æ‰§è¡Œé€‰è‚¡æµç¨‹
        
        Args:
            max_stocks: æœ€å¤§é€‰æ‹©è‚¡ç¥¨æ•°é‡
            
        Returns:
            (é€‰ä¸­çš„è‚¡ç¥¨DataFrame, é€‰è‚¡ç»Ÿè®¡ä¿¡æ¯)
        """
        logger.info("å¼€å§‹æ‰§è¡Œé€‰è‚¡æµç¨‹...")
        
        # 1. è·å–å¸‚åœºæ•°æ®
        market_data = self.get_market_data()

        # 2. æ£€æŸ¥å¸‚åœºç¯å¢ƒ
        is_good_market, up_ratio = self.check_market_environment(market_data)
        
        stats = {
            'total_stocks': len(market_data),
            'up_ratio': up_ratio,
            'is_good_market': is_good_market,
            'selection_time': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # å¦‚æœå¸‚åœºç¯å¢ƒä¸ä½³ï¼Œè¿”å›ç©ºç»“æœ (ä½†å…è®¸é¢„å¼€ç›˜ç­›é€‰)
        if not is_good_market and up_ratio != 0.5:
            logger.warning("å¸‚åœºç¯å¢ƒä¸ä½³ï¼Œä¸è¿›è¡Œé€‰è‚¡")
            return pd.DataFrame(), stats
        
        # 3. è¿‡æ»¤é£é™©è‚¡ç¥¨
        filtered_data = self.filter_risk_stocks(market_data)
        stats['after_risk_filter'] = len(filtered_data)
        
        # 4. åº”ç”¨é€‰è‚¡æ ‡å‡†
        selected_stocks = self.apply_selection_criteria(filtered_data)
        stats['after_criteria_filter'] = len(selected_stocks)
        
        # 5. æ’åºè‚¡ç¥¨
        ranked_stocks = self.rank_stocks(selected_stocks)
        
        # 6. é™åˆ¶æ•°é‡
        final_stocks = ranked_stocks.head(max_stocks)
        stats['final_selection'] = len(final_stocks)
        
        logger.info(f"é€‰è‚¡å®Œæˆï¼Œæœ€ç»ˆé€‰å‡º {len(final_stocks)} åªè‚¡ç¥¨")
        
        return final_stocks, stats
    
    def display_results(self, selected_stocks: pd.DataFrame, stats: Dict):
        """
        æ˜¾ç¤ºé€‰è‚¡ç»“æœ
        
        Args:
            selected_stocks: é€‰ä¸­çš„è‚¡ç¥¨DataFrame
            stats: é€‰è‚¡ç»Ÿè®¡ä¿¡æ¯
        """
        print("\n" + "="*60)
        print("ğŸ“Š æ—©ç›˜é‡åŒ–é€‰è‚¡ç»“æœ")
        print("="*60)
        
        print(f"é€‰è‚¡æ—¶é—´: {stats['selection_time']}")
        print(f"å¸‚åœºæ€»è‚¡ç¥¨æ•°: {stats['total_stocks']}")
        print(f"å¸‚åœºä¸Šæ¶¨å®¶æ•°å æ¯”: {stats['up_ratio']:.2%}")
        print(f"å¸‚åœºç¯å¢ƒè¯„ä¼°: {'âœ… é€‚åˆé€‰è‚¡' if stats['is_good_market'] else 'âŒ ä¸é€‚åˆé€‰è‚¡'}")
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºå¸‚åœºå¼€ç›˜å‰çš„æƒ…å†µ
        is_pre_market = stats['up_ratio'] == 0.5 and stats['is_good_market']
        
        if not stats['is_good_market'] and not is_pre_market:
            print("\nâš ï¸  å¸‚åœºç¯å¢ƒä¸ä½³ï¼Œå»ºè®®è§‚æœ›")
            return
        
        if is_pre_market:
            print("\nğŸ“¢ å½“å‰ä¸ºå¸‚åœºå¼€ç›˜å‰ï¼ŒåŸºäºæ˜¨æ—¥æ•°æ®è¿›è¡ŒåŸºç¡€ç­›é€‰")
        
        print("\nç­›é€‰è¿‡ç¨‹:")
        print(f"  é£é™©è‚¡ç¥¨è¿‡æ»¤å: {stats['after_risk_filter']} åª")
        print(f"  é€‰è‚¡æ ‡å‡†è¿‡æ»¤å: {stats['after_criteria_filter']} åª")
        print(f"  æœ€ç»ˆé€‰ä¸­: {stats['final_selection']} åª")
        
        if len(selected_stocks) > 0:
            if is_pre_market:
                print(f"\nğŸ¯ é¢„é€‰ {len(selected_stocks)} åªæ½œåŠ›è‚¡ï¼ˆå¾…å¼€ç›˜ç¡®è®¤ï¼‰:")
            else:
                print(f"\nğŸ¯ ä»Šæ—¥ç²¾é€‰ {len(selected_stocks)} åªæ½œåŠ›è‚¡:")
            print("-" * 60)
            
            # æ˜¾ç¤ºä¸»è¦å­—æ®µï¼Œå¤„ç†åˆ—åå·®å¼‚
            for idx, (_, stock) in enumerate(selected_stocks.iterrows(), 1):
                # è·å–ä»·æ ¼
                price = None
                if 'æœ€æ–°ä»·' in selected_stocks.columns and pd.notna(stock['æœ€æ–°ä»·']):
                    price = stock['æœ€æ–°ä»·']
                elif 'æœ€æ–°' in selected_stocks.columns and pd.notna(stock['æœ€æ–°']):
                    price = stock['æœ€æ–°']
                elif 'æ˜¨æ”¶' in selected_stocks.columns and pd.notna(stock['æ˜¨æ”¶']):
                    price = stock['æ˜¨æ”¶']
                
                # è·å–æ¶¨å¹…
                gain = None
                if 'æ¶¨å¹…' in selected_stocks.columns and pd.notna(stock['æ¶¨å¹…']):
                    gain = stock['æ¶¨å¹…']
                elif 'æ¶¨è·Œå¹…' in selected_stocks.columns and pd.notna(stock['æ¶¨è·Œå¹…']):
                    gain = stock['æ¶¨è·Œå¹…']
                
                market_cap_yi = stock['æµé€šå¸‚å€¼'] / 1e8 if pd.notna(stock['æµé€šå¸‚å€¼']) else 0
                
                # æ„å»ºæ˜¾ç¤ºå­—ç¬¦ä¸²
                info_parts = [f"{idx:2d}. {stock['ä»£ç ']} {stock['åç§°']:8s}"]
                
                if price:
                    info_parts.append(f"ä»·æ ¼:{price:6.2f}")
                
                if gain is not None:
                    if is_pre_market and gain == 0:
                        info_parts.append("æ¶¨å¹…:å¾…å¼€ç›˜")
                    else:
                        info_parts.append(f"æ¶¨å¹…:{gain:5.2f}%")
                
                if 'å¸‚ç›ˆç‡' in selected_stocks.columns and pd.notna(stock['å¸‚ç›ˆç‡']):
                    info_parts.append(f"PE:{stock['å¸‚ç›ˆç‡']:5.1f}")
                
                info_parts.append(f"å¸‚å€¼:{market_cap_yi:6.1f}äº¿")
                
                if 'ç»¼åˆå¾—åˆ†' in selected_stocks.columns and pd.notna(stock['ç»¼åˆå¾—åˆ†']):
                    info_parts.append(f"å¾—åˆ†:{stock['ç»¼åˆå¾—åˆ†']:4.2f}")
                
                print(" ".join(info_parts))
        
        print("\n" + "="*60)
        if is_pre_market:
            print("âš ï¸  é£é™©æç¤º: è¿™æ˜¯å¼€ç›˜å‰çš„é¢„é€‰ç»“æœï¼Œè¯·åœ¨å¼€ç›˜åç»“åˆå®æ—¶è¡Œæƒ…å†æ¬¡ç¡®è®¤ï¼")
            print("ğŸ“ å»ºè®®: å…³æ³¨è¿™äº›è‚¡ç¥¨çš„å¼€ç›˜è¡¨ç°ï¼Œè®¾ç½®åˆç†çš„ä¹°å…¥ä»·ä½")
        else:
            print("âš ï¸  é£é™©æç¤º: æŠ•èµ„æœ‰é£é™©ï¼Œäº¤æ˜“éœ€è°¨æ…ï¼")
            print("ğŸ“ å»ºè®®: ç»“åˆåŸºæœ¬é¢åˆ†æï¼Œè®¾ç½®æ­¢æŸç‚¹ï¼Œæ§åˆ¶ä»“ä½")
        print("="*60)
    
    def _standardize_tushare_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ ‡å‡†åŒ–Tushareæ•°æ®åˆ—å
        
        Args:
            df: Tushareæ•°æ®DataFrame
            
        Returns:
            æ ‡å‡†åŒ–åçš„DataFrame
        """
        # Tushareå­—æ®µæ˜ å°„åˆ°æ ‡å‡†æ ¼å¼
        tushare_column_mapping = {
            'ts_code': 'ä»£ç ',
            'symbol': 'ä»£ç ',
            'name': 'åç§°',
            'close': 'æœ€æ–°',
            'open': 'ä»Šå¼€',
            'high': 'æœ€é«˜',
            'low': 'æœ€ä½',
            'pre_close': 'æ˜¨æ”¶',
            'change': 'æ¶¨è·Œ',
            'pct_chg': 'æ¶¨å¹…',
            'vol': 'æˆäº¤é‡',
            'amount': 'æˆäº¤é¢',
            'turnover_rate': 'æ¢æ‰‹ç‡'
        }
        
        # é‡å‘½ååˆ—
        df_clean = df.copy()
        for old_col, new_col in tushare_column_mapping.items():
            if old_col in df_clean.columns:
                df_clean = df_clean.rename(columns={old_col: new_col})
        
        # å¤„ç†ä»£ç æ ¼å¼ï¼ˆTushareæ ¼å¼ä¸º000001.SZï¼Œéœ€è¦è½¬æ¢ä¸º000001ï¼‰
        if 'ä»£ç ' in df_clean.columns:
            df_clean['ä»£ç '] = df_clean['ä»£ç '].astype(str).str.split('.').str[0]
        
        # è®¡ç®—ç¼ºå¤±çš„å­—æ®µ
        if 'æ¶¨å¹…' in df_clean.columns:
            df_clean['æ¶¨å¹…'] = pd.to_numeric(df_clean['æ¶¨å¹…'], errors='coerce')
        
        # ä¼°ç®—å¸‚ç›ˆç‡ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
        if 'æœ€æ–°' in df_clean.columns and 'å¸‚ç›ˆç‡' not in df_clean.columns:
            df_clean['å¸‚ç›ˆç‡'] = 15.0  # ä½¿ç”¨å¹³å‡å¸‚ç›ˆç‡
        
        # ä¼°ç®—é‡æ¯”ï¼ˆç®€åŒ–å¤„ç†ï¼‰
        if 'é‡æ¯”' not in df_clean.columns:
            df_clean['é‡æ¯”'] = 1.0
        
        # ä¼°ç®—æ€»å¸‚å€¼å’Œæµé€šå¸‚å€¼ï¼ˆéœ€è¦è·å–è‚¡æœ¬æ•°æ®ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
        if 'æ€»å¸‚å€¼' not in df_clean.columns and 'æœ€æ–°' in df_clean.columns:
            df_clean['æ€»å¸‚å€¼'] = 1e10  # ç®€åŒ–ä¸º100äº¿
            df_clean['æµé€šå¸‚å€¼'] = 8e9  # ç®€åŒ–ä¸º80äº¿
        
        return df_clean
    
    def _standardize_akshare_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ ‡å‡†åŒ–akshareæ•°æ®åˆ—å
        
        Args:
            df: akshareæ•°æ®DataFrame
            
        Returns:
            æ ‡å‡†åŒ–åçš„DataFrame
        """
        akshare_column_mapping = {
            'ä»£ç ': 'ä»£ç ',
            'åç§°': 'åç§°', 
            'æ¶¨è·Œå¹…': 'æ¶¨å¹…',
            'æœ€æ–°ä»·': 'æœ€æ–°',
            'æœ€é«˜': 'æœ€é«˜',
            'æœ€ä½': 'æœ€ä½',
            'ä»Šå¼€': 'ä»Šå¼€',
            'æ¢æ‰‹ç‡': 'æ¢æ‰‹ç‡',
            'é‡æ¯”': 'é‡æ¯”',
            'å¸‚ç›ˆç‡-åŠ¨æ€': 'å¸‚ç›ˆç‡',
            'æˆäº¤é‡': 'æˆäº¤é‡',
            'æˆäº¤é¢': 'æˆäº¤é¢',
            'æ˜¨æ”¶': 'æ˜¨æ”¶',
            'æ€»å¸‚å€¼': 'æ€»å¸‚å€¼',
            'æµé€šå¸‚å€¼': 'æµé€šå¸‚å€¼'
        }
        
        # é‡å‘½ååˆ—ä»¥ä¿æŒä¸€è‡´æ€§
        df_clean = df.copy()
        for old_col, new_col in akshare_column_mapping.items():
            if old_col in df_clean.columns and old_col != new_col:
                df_clean = df_clean.rename(columns={old_col: new_col})
        
        return df_clean

    # ...existing code...
def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºé€‰è‚¡æµç¨‹"""
    # åˆ›å»ºè‚¡ç¥¨é€‰æ‹©å™¨å®ä¾‹
    picker = BaseStockPicker()
    
    # æ‰§è¡Œé€‰è‚¡
    try:
        selected_stocks, stats = picker.select_stocks(max_stocks=8)
        
        # æ˜¾ç¤ºç»“æœ
        picker.display_results(selected_stocks, stats)
        
        # ä¿å­˜ç»“æœï¼ˆå¯é€‰ï¼‰
        if len(selected_stocks) > 0:
            filename = f"/tmp/itrading/selected_stocks_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            selected_stocks.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"\nğŸ’¾ é€‰è‚¡ç»“æœå·²ä¿å­˜è‡³: {filename}")
            
    except Exception as e:
        logger.error(f"é€‰è‚¡è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print(f"âŒ é€‰è‚¡å¤±è´¥: {e}")


if __name__ == "__main__":
    main()
